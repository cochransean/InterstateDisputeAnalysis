{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_data():\n",
    "    disputes = pd.read_csv('data/MIDB_4.01.csv')\n",
    "    states_by_year = pd.read_csv('data/system2011.csv') # State membership in each year of dataset\n",
    "\n",
    "    # Get rid of columns we don't care about\n",
    "    disputes = disputes.loc[:, ['DispNum3', 'StAbb', 'ccode', 'StYear', 'EndYear', 'Orig', 'Fatality', 'FataPre', \n",
    "                                'HiAct', 'HostLev']]\n",
    "    states_by_year = states_by_year.loc[:, ['stateabb', 'ccode', 'year']]\n",
    "    \n",
    "    # Only include hostile acts where force was used, not just displayed or threatened\n",
    "    disputes = disputes[disputes['HostLev'] >= 4]\n",
    "    \n",
    "    return disputes, states_by_year, country_codes\n",
    "\n",
    "disputes, states_by_year, country_codes = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_membership_sets(states_by_year):\n",
    "    years = states_by_year['year'].unique()\n",
    "\n",
    "    # Make a dict to track state membership by year\n",
    "    membership = defaultdict(set)\n",
    "\n",
    "    # Add states that existed each year to dict\n",
    "    for year in years:\n",
    "        membership[year].update(states_by_year[states_by_year['year'] == year]['ccode'])\n",
    "    \n",
    "    return membership\n",
    "        \n",
    "membership = get_membership_sets(states_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year: 1816\n",
      "Processing year: 1817\n",
      "Processing year: 1818\n",
      "Processing year: 1819\n",
      "Processing year: 1820\n",
      "Processing year: 1821\n",
      "Processing year: 1822\n",
      "Processing year: 1823\n",
      "Processing year: 1824\n",
      "Processing year: 1825\n",
      "Processing year: 1826\n",
      "Processing year: 1827\n",
      "Processing year: 1828\n",
      "Processing year: 1829\n",
      "Processing year: 1830\n",
      "Processing year: 1831\n",
      "Processing year: 1832\n",
      "Processing year: 1833\n",
      "Processing year: 1834\n",
      "Processing year: 1835\n",
      "Processing year: 1836\n",
      "Processing year: 1837\n",
      "Processing year: 1838\n",
      "Processing year: 1839\n",
      "Processing year: 1840\n",
      "Processing year: 1841\n",
      "Processing year: 1842\n",
      "Processing year: 1843\n",
      "Processing year: 1844\n",
      "Processing year: 1845\n",
      "Processing year: 1846\n",
      "Processing year: 1847\n",
      "Processing year: 1848\n",
      "Processing year: 1849\n",
      "Processing year: 1850\n",
      "Processing year: 1851\n",
      "Processing year: 1852\n",
      "Processing year: 1853\n",
      "Processing year: 1854\n",
      "Processing year: 1855\n",
      "Processing year: 1856\n",
      "Processing year: 1857\n",
      "Processing year: 1858\n",
      "Processing year: 1859\n",
      "Processing year: 1860\n",
      "Processing year: 1861\n",
      "Processing year: 1862\n",
      "Processing year: 1863\n",
      "Processing year: 1864\n",
      "Processing year: 1865\n",
      "Processing year: 1866\n",
      "Processing year: 1867\n",
      "Processing year: 1868\n",
      "Processing year: 1869\n",
      "Processing year: 1870\n",
      "Processing year: 1871\n",
      "Processing year: 1872\n",
      "Processing year: 1873\n",
      "Processing year: 1874\n",
      "Processing year: 1875\n",
      "Processing year: 1876\n",
      "Processing year: 1877\n",
      "Processing year: 1878\n",
      "Processing year: 1879\n",
      "Processing year: 1880\n",
      "Processing year: 1881\n",
      "Processing year: 1882\n",
      "Processing year: 1883\n",
      "Processing year: 1884\n",
      "Processing year: 1885\n",
      "Processing year: 1886\n",
      "Processing year: 1887\n",
      "Processing year: 1888\n",
      "Processing year: 1889\n",
      "Processing year: 1890\n",
      "Processing year: 1891\n",
      "Processing year: 1892\n",
      "Processing year: 1893\n",
      "Processing year: 1894\n",
      "Processing year: 1895\n",
      "Processing year: 1896\n",
      "Processing year: 1897\n",
      "Processing year: 1898\n",
      "Processing year: 1899\n",
      "Processing year: 1900\n",
      "Processing year: 1901\n",
      "Processing year: 1902\n",
      "Processing year: 1903\n",
      "Processing year: 1904\n",
      "Processing year: 1905\n",
      "Processing year: 1906\n",
      "Processing year: 1907\n",
      "Processing year: 1908\n",
      "Processing year: 1909\n",
      "Processing year: 1910\n",
      "Processing year: 1911\n",
      "Processing year: 1912\n",
      "Processing year: 1913\n",
      "Processing year: 1914\n",
      "Processing year: 1915\n",
      "Processing year: 1916\n",
      "Processing year: 1917\n",
      "Processing year: 1918\n",
      "Processing year: 1919\n",
      "Processing year: 1920\n",
      "Processing year: 1921\n",
      "Processing year: 1922\n",
      "Processing year: 1923\n",
      "Processing year: 1924\n",
      "Processing year: 1925\n",
      "Processing year: 1926\n",
      "Processing year: 1927\n",
      "Processing year: 1928\n",
      "Processing year: 1929\n",
      "Processing year: 1930\n",
      "Processing year: 1931\n",
      "Processing year: 1932\n",
      "Processing year: 1933\n",
      "Processing year: 1934\n",
      "Processing year: 1935\n",
      "Processing year: 1936\n",
      "Processing year: 1937\n",
      "Processing year: 1938\n",
      "Processing year: 1939\n",
      "Processing year: 1940\n",
      "Processing year: 1941\n",
      "Processing year: 1942\n",
      "Processing year: 1943\n",
      "Processing year: 1944\n",
      "Processing year: 1945\n",
      "Processing year: 1946\n",
      "Processing year: 1947\n",
      "Processing year: 1948\n",
      "Processing year: 1949\n",
      "Processing year: 1950\n",
      "Processing year: 1951\n",
      "Processing year: 1952\n",
      "Processing year: 1953\n",
      "Processing year: 1954\n",
      "Processing year: 1955\n",
      "Processing year: 1956\n",
      "Processing year: 1957\n",
      "Processing year: 1958\n",
      "Processing year: 1959\n",
      "Processing year: 1960\n",
      "Processing year: 1961\n",
      "Processing year: 1962\n",
      "Processing year: 1963\n",
      "Processing year: 1964\n",
      "Processing year: 1965\n",
      "Processing year: 1966\n",
      "Processing year: 1967\n",
      "Processing year: 1968\n",
      "Processing year: 1969\n",
      "Processing year: 1970\n",
      "Processing year: 1971\n",
      "Processing year: 1972\n",
      "Processing year: 1973\n",
      "Processing year: 1974\n",
      "Processing year: 1975\n",
      "Processing year: 1976\n",
      "Processing year: 1977\n",
      "Processing year: 1978\n",
      "Processing year: 1979\n",
      "Processing year: 1980\n",
      "Processing year: 1981\n",
      "Processing year: 1982\n",
      "Processing year: 1983\n",
      "Processing year: 1984\n",
      "Processing year: 1985\n",
      "Processing year: 1986\n",
      "Processing year: 1987\n",
      "Processing year: 1988\n",
      "Processing year: 1989\n",
      "Processing year: 1990\n",
      "Processing year: 1991\n",
      "Processing year: 1992\n",
      "Processing year: 1993\n",
      "Processing year: 1994\n",
      "Processing year: 1995\n",
      "Processing year: 1996\n",
      "Processing year: 1997\n",
      "Processing year: 1998\n",
      "Processing year: 1999\n",
      "Processing year: 2000\n",
      "Processing year: 2001\n",
      "Processing year: 2002\n",
      "Processing year: 2003\n",
      "Processing year: 2004\n",
      "Processing year: 2005\n",
      "Processing year: 2006\n",
      "Processing year: 2007\n",
      "Processing year: 2008\n",
      "Processing year: 2009\n",
      "Processing year: 2010\n",
      "Processing year: 2011\n"
     ]
    }
   ],
   "source": [
    "def get_total_possible_conflicts(disputes, membership_by_year):\n",
    "    \n",
    "    # Add each \"opportunity\" for conflict, where two states existed and might have fought in a given year\n",
    "    new_data = list()\n",
    "    \n",
    "    for year in membership_by_year:\n",
    "        print('Processing year: {}'.format(year))\n",
    "        yearly_disputes = disputes[disputes['StYear'] == year]\n",
    "        for country in membership_by_year[year]:\n",
    "            for potential_opponent in membership_by_year[year] - set([country]):\n",
    "            \n",
    "                # Find any conflicts the given country was in\n",
    "                conflicts = set(yearly_disputes[disputes['ccode'] == country]['DispNum3'])\n",
    "\n",
    "                # Find parties on the opposite side of the conflict\n",
    "                actual_opponents = set(disputes[(disputes['DispNum3'].isin(conflicts)) & \n",
    "                                                (disputes['ccode'] != country)]['ccode'])\n",
    "\n",
    "                # Create an entry for each pair of countries that could have had a conflict in the dataset\n",
    "                new_data.append({\n",
    "                    'ccode': country,\n",
    "                    'ccode_potential_opponent': potential_opponent,\n",
    "                    'fought_potential_opponent': potential_opponent in actual_opponents,\n",
    "                    'year': year\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(new_data)\n",
    "\n",
    "total_possible_conflicts = get_total_possible_conflicts(disputes, membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save dyad pairs since constructing them is time intensive\n",
    "total_possible_conflicts.to_csv('data/total_possible_conflicts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_data(conflicts):\n",
    "    \n",
    "    # Add materiel capabilities\n",
    "    nmc = pd.read_csv('data/NMC_v4_0.csv').loc[:, ['stateabb', 'ccode', 'year', 'cinc']]\n",
    "    conflicts = pd.merge(left=conflicts, right=nmc, left_on=['ccode', 'year'], right_on=['ccode', 'year'])\n",
    "    conflicts = pd.merge(left=conflicts, right=nmc, left_on=['ccode_potential_opponent', 'year'],                 \n",
    "                         right_on=['ccode', 'year'], suffixes=('', '_potential_opponent'))\n",
    "\n",
    "    # Merge with country code names to get the full state name\n",
    "    country_codes = pd.read_csv('data/COW country codes.csv').drop_duplicates()\n",
    "    country_codes = country_codes.loc[:, ['StateAbb', 'StateNme']]\n",
    "    conflicts = pd.merge(left=conflicts, right=country_codes, left_on='stateabb', right_on='StateAbb')\n",
    "    conflicts = pd.merge(left=conflicts, right=country_codes, left_on='stateabb_potential_opponent', \n",
    "                         right_on='StateAbb', suffixes=('', '_potential_opponent'))\n",
    "    \n",
    "    # Drop duplicated columns\n",
    "    conflicts = conflicts.loc[:, [not x for x in conflicts.columns.duplicated()]]\n",
    "    \n",
    "    \n",
    "    # Add alliance data\n",
    "    alliances = pd.read_csv('data/alliance_v4.1_by_directed_yearly.csv').loc[:, ['ccode1', 'ccode2', 'defense',\n",
    "                                                                                 'neutrality', 'nonaggression',\n",
    "                                                                                 'entente', 'year']]\n",
    "    conflicts = pd.merge(left=conflicts, right=alliances, left_on=['ccode', 'ccode_potential_opponent', 'year'], \n",
    "                         right_on=['ccode1', 'ccode2', 'year'])\n",
    "    \n",
    "    # Add contiguity data\n",
    "    contiguity_data = pd.read_csv('data/contdird.csv')\n",
    "    conflicts = pd.merge(left=conflicts, right=contiguity_data, left_on=['ccode', 'ccode_potential_opponent', 'year'],\n",
    "                         right_on=['state1no', 'state2no', 'year'], how=\"left\")\n",
    "    # Add a new categorical value to indicate countries with no contiguity relationship in dataset\n",
    "    conflicts['conttype'] = conflicts['conttype'].fillna(6)\n",
    "    \n",
    "    # Add trade data\n",
    "    trade_data = pd.read_csv('data/Dyadic_COW_4.0.csv').loc[:, ['ccode1', 'ccode2', 'year', 'flow1', 'flow2']]\n",
    "    conflicts = pd.merge(left=conflicts, right=trade_data, left_on=['ccode', 'ccode_potential_opponent', 'year'],\n",
    "                         right_on=['ccode1', 'ccode2', 'year'], suffixes=('', '_extra'))\n",
    "    \n",
    "    return conflicts.loc[:, ['ccode', 'ccode_potential_opponent', 'fought_potential_opponent', 'year', 'stateabb', \n",
    "                             'cinc', 'stateabb_potential_opponent', 'cinc_potential_opponent', 'StateNme',\n",
    "                             'StateNme_potential_opponent', 'defense', 'neutrality', 'nonaggression', 'entente', \n",
    "                             'conttype', 'flow1', 'flow2']]\n",
    "\n",
    "conflicts_with_data = add_data(total_possible_conflicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_data(conflicts):\n",
    "    \n",
    "    # Since -9 marks missing values in dataset\n",
    "    conflicts = conflicts[(conflicts_with_data.values != -9).any(axis=1)]\n",
    "    conflicts = conflicts.dropna()\n",
    "    conflicts = conflicts.drop_duplicates(subset=['ccode', 'ccode_potential_opponent', 'year'])\n",
    "    \n",
    "    # Dummify the contiguity data\n",
    "    conflicts = pd.get_dummies(conflicts, columns=['conttype'])\n",
    "    \n",
    "    return conflicts\n",
    "\n",
    "conflicts_cleaned = clean_data(conflicts_with_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year: 1800\n",
      "Processing year: 1801\n",
      "Processing year: 1816\n",
      "Processing year: 1817\n",
      "Processing year: 1818\n",
      "Processing year: 1819\n",
      "Processing year: 1820\n",
      "Processing year: 1821\n",
      "Processing year: 1822\n",
      "Processing year: 1823\n",
      "Processing year: 1824\n",
      "Processing year: 1825\n",
      "Processing year: 1826\n",
      "Processing year: 1827\n",
      "Processing year: 1828\n",
      "Processing year: 1829\n",
      "Processing year: 1830\n",
      "Processing year: 1831\n",
      "Processing year: 1832\n",
      "Processing year: 1833\n",
      "Processing year: 1834\n",
      "Processing year: 1835\n",
      "Processing year: 1836\n",
      "Processing year: 1837\n",
      "Processing year: 1838\n",
      "Processing year: 1839\n",
      "Processing year: 1840\n",
      "Processing year: 1841\n",
      "Processing year: 1842\n",
      "Processing year: 1843\n",
      "Processing year: 1844\n",
      "Processing year: 1845\n",
      "Processing year: 1846\n",
      "Processing year: 1847\n",
      "Processing year: 1848\n",
      "Processing year: 1849\n",
      "Processing year: 1850\n",
      "Processing year: 1851\n",
      "Processing year: 1852\n",
      "Processing year: 1853\n",
      "Processing year: 1854\n",
      "Processing year: 1855\n",
      "Processing year: 1856\n",
      "Processing year: 1857\n",
      "Processing year: 1858\n",
      "Processing year: 1859\n",
      "Processing year: 1860\n",
      "Processing year: 1861\n",
      "Processing year: 1862\n",
      "Processing year: 1863\n",
      "Processing year: 1864\n",
      "Processing year: 1865\n",
      "Processing year: 1866\n",
      "Processing year: 1867\n",
      "Processing year: 1868\n",
      "Processing year: 1869\n",
      "Processing year: 1870\n",
      "Processing year: 1871\n",
      "Processing year: 1872\n",
      "Processing year: 1873\n",
      "Processing year: 1874\n",
      "Processing year: 1875\n",
      "Processing year: 1876\n",
      "Processing year: 1877\n",
      "Processing year: 1878\n",
      "Processing year: 1879\n",
      "Processing year: 1880\n",
      "Processing year: 1881\n",
      "Processing year: 1882\n",
      "Processing year: 1883\n",
      "Processing year: 1884\n",
      "Processing year: 1885\n",
      "Processing year: 1886\n",
      "Processing year: 1887\n",
      "Processing year: 1888\n",
      "Processing year: 1889\n",
      "Processing year: 1890\n",
      "Processing year: 1891\n",
      "Processing year: 1892\n",
      "Processing year: 1893\n",
      "Processing year: 1894\n",
      "Processing year: 1895\n",
      "Processing year: 1896\n",
      "Processing year: 1897\n",
      "Processing year: 1898\n",
      "Processing year: 1899\n",
      "Processing year: 1900\n",
      "Processing year: 1901\n",
      "Processing year: 1902\n",
      "Processing year: 1903\n",
      "Processing year: 1904\n",
      "Processing year: 1905\n",
      "Processing year: 1906\n",
      "Processing year: 1907\n",
      "Processing year: 1908\n",
      "Processing year: 1909\n",
      "Processing year: 1910\n",
      "Processing year: 1911\n",
      "Processing year: 1912\n",
      "Processing year: 1913\n",
      "Processing year: 1914\n",
      "Processing year: 1915\n",
      "Processing year: 1916\n",
      "Processing year: 1917\n",
      "Processing year: 1918\n",
      "Processing year: 1919\n",
      "Processing year: 1920\n",
      "Processing year: 1921\n",
      "Processing year: 1922\n",
      "Processing year: 1923\n",
      "Processing year: 1924\n",
      "Processing year: 1925\n",
      "Processing year: 1926\n",
      "Processing year: 1927\n",
      "Processing year: 1928\n",
      "Processing year: 1929\n",
      "Processing year: 1930\n",
      "Processing year: 1931\n",
      "Processing year: 1932\n",
      "Processing year: 1933\n",
      "Processing year: 1934\n",
      "Processing year: 1935\n",
      "Processing year: 1936\n",
      "Processing year: 1937\n",
      "Processing year: 1938\n",
      "Processing year: 1939\n",
      "Processing year: 1940\n",
      "Processing year: 1941\n",
      "Processing year: 1942\n",
      "Processing year: 1943\n",
      "Processing year: 1944\n",
      "Processing year: 1945\n",
      "Processing year: 1946\n",
      "Processing year: 1947\n",
      "Processing year: 1948\n",
      "Processing year: 1949\n",
      "Processing year: 1950\n",
      "Processing year: 1951\n",
      "Processing year: 1952\n",
      "Processing year: 1953\n",
      "Processing year: 1954\n",
      "Processing year: 1955\n",
      "Processing year: 1956\n",
      "Processing year: 1957\n",
      "Processing year: 1958\n",
      "Processing year: 1959\n",
      "Processing year: 1960\n",
      "Processing year: 1961\n",
      "Processing year: 1962\n",
      "Processing year: 1963\n",
      "Processing year: 1964\n",
      "Processing year: 1965\n",
      "Processing year: 1966\n",
      "Processing year: 1967\n",
      "Processing year: 1968\n",
      "Processing year: 1969\n",
      "Processing year: 1970\n",
      "Processing year: 1971\n",
      "Processing year: 1972\n",
      "Processing year: 1973\n",
      "Processing year: 1974\n",
      "Processing year: 1975\n",
      "Processing year: 1976\n",
      "Processing year: 1977\n",
      "Processing year: 1978\n",
      "Processing year: 1979\n",
      "Processing year: 1980\n",
      "Processing year: 1981\n",
      "Processing year: 1982\n",
      "Processing year: 1983\n",
      "Processing year: 1984\n",
      "Processing year: 1985\n",
      "Processing year: 1986\n",
      "Processing year: 1987\n",
      "Processing year: 1988\n",
      "Processing year: 1989\n",
      "Processing year: 1990\n",
      "Processing year: 1991\n",
      "Processing year: 1992\n",
      "Processing year: 1993\n",
      "Processing year: 1994\n",
      "Processing year: 1995\n",
      "Processing year: 1996\n",
      "Processing year: 1997\n",
      "Processing year: 1998\n",
      "Processing year: 1999\n",
      "Processing year: 2000\n",
      "Processing year: 2001\n",
      "Processing year: 2002\n",
      "Processing year: 2003\n",
      "Processing year: 2004\n",
      "Processing year: 2005\n",
      "Processing year: 2006\n",
      "Processing year: 2007\n",
      "Processing year: 2008\n",
      "Processing year: 2009\n",
      "Processing year: 2010\n",
      "Processing year: 2011\n"
     ]
    }
   ],
   "source": [
    "def tally_alliance_power(conflicts, membership_by_year):\n",
    "    \"\"\"Returns a new dataframe with alliance power by year.\"\"\"\n",
    "    \n",
    "    alliance_powers = list()\n",
    "    \n",
    "    # Tally the strength of alliances on each side and add to the data\n",
    "    for year in membership_by_year:\n",
    "        print('Processing year: {}'.format(year))\n",
    "        yearly_data = conflicts[conflicts['year'] == year]\n",
    "        for country in membership_by_year[year]:\n",
    "            # Select using potential opponents since data is organized for the \"receiver\" of a deal\n",
    "            # to be the country promised defense by the other\n",
    "            alliance_power = yearly_data[(yearly_data['ccode_potential_opponent'] == country) & \n",
    "                                       (yearly_data['defense'] == 1)]['cinc'].sum()\n",
    "            alliance_powers.append({\n",
    "                'year': year,\n",
    "                'ccode': country,\n",
    "                'allies_power': alliance_power\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(alliance_powers)\n",
    "            \n",
    "alliance_powers_df = tally_alliance_power(conflicts_cleaned, membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_alliance_power(conflicts, alliance_powers):\n",
    "\n",
    "    # Merge alliance powers with existing conflict data\n",
    "    conflicts = pd.merge(left=conflicts, right=alliance_powers, left_on=['ccode', 'year'],\n",
    "                         right_on=['ccode', 'year'])\n",
    "    conflicts = pd.merge(left=conflicts, right=alliance_powers, left_on=['ccode_potential_opponent', 'year'],\n",
    "                     right_on=['ccode', 'year'], suffixes=('', '_potential_opponent'))\n",
    "    \n",
    "    # Remove extra columns\n",
    "    conflicts = conflicts.loc[:, [not x for x in conflicts.columns.duplicated()]]\n",
    "    return conflicts\n",
    "    \n",
    "potential_conflicts_prepped = add_alliance_power(conflicts_cleaned, alliance_powers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.062100\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>fought_potential_opponent</td> <th>  No. Observations:  </th>   <td> 51226</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>Logit</td>           <th>  Df Residuals:      </th>   <td> 51210</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                   <td>MLE</td>            <th>  Df Model:          </th>   <td>    15</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Sat, 11 Mar 2017</td>      <th>  Pseudo R-squ.:     </th>   <td>0.09718</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>16:31:22</td>          <th>  Log-Likelihood:    </th>  <td> -3181.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>               <td>True</td>            <th>  LL-Null:           </th>  <td> -3523.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                          <td> </td>             <th>  LLR p-value:       </th> <td>3.173e-136</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cinc</th>                            <td>    5.0679</td> <td>    0.635</td> <td>    7.979</td> <td> 0.000</td> <td>    3.823     6.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cinc_potential_opponent</th>         <td>    7.7708</td> <td>    1.091</td> <td>    7.122</td> <td> 0.000</td> <td>    5.632     9.909</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>defense</th>                         <td>   -0.5988</td> <td>    0.115</td> <td>   -5.206</td> <td> 0.000</td> <td>   -0.824    -0.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>neutrality</th>                      <td>    0.3321</td> <td>    0.158</td> <td>    2.104</td> <td> 0.035</td> <td>    0.023     0.641</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nonaggression</th>                   <td>   -0.4187</td> <td>    0.088</td> <td>   -4.743</td> <td> 0.000</td> <td>   -0.592    -0.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>entente</th>                         <td>   -0.3567</td> <td>    0.110</td> <td>   -3.254</td> <td> 0.001</td> <td>   -0.572    -0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flow1</th>                           <td>-4.528e-05</td> <td> 1.01e-05</td> <td>   -4.464</td> <td> 0.000</td> <td>-6.52e-05 -2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flow2</th>                           <td> 7.236e-05</td> <td>  1.2e-05</td> <td>    6.016</td> <td> 0.000</td> <td> 4.88e-05  9.59e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>conttype_1.0</th>                    <td>    1.2513</td> <td>    0.094</td> <td>   13.352</td> <td> 0.000</td> <td>    1.068     1.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>conttype_2.0</th>                    <td>    1.8963</td> <td>    0.425</td> <td>    4.464</td> <td> 0.000</td> <td>    1.064     2.729</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>conttype_3.0</th>                    <td>    1.7363</td> <td>    0.238</td> <td>    7.285</td> <td> 0.000</td> <td>    1.269     2.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>conttype_4.0</th>                    <td>    0.6842</td> <td>    0.240</td> <td>    2.848</td> <td> 0.004</td> <td>    0.213     1.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>conttype_5.0</th>                    <td>    0.6997</td> <td>    0.169</td> <td>    4.135</td> <td> 0.000</td> <td>    0.368     1.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>allies_power</th>                    <td>   -1.1480</td> <td>    0.592</td> <td>   -1.939</td> <td> 0.053</td> <td>   -2.309     0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>allies_power_potential_opponent</th> <td>    2.9889</td> <td>    0.543</td> <td>    5.502</td> <td> 0.000</td> <td>    1.924     4.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>                       <td>   -4.3954</td> <td>    0.141</td> <td>  -31.262</td> <td> 0.000</td> <td>   -4.671    -4.120</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                               Logit Regression Results                              \n",
       "=====================================================================================\n",
       "Dep. Variable:     fought_potential_opponent   No. Observations:                51226\n",
       "Model:                                 Logit   Df Residuals:                    51210\n",
       "Method:                                  MLE   Df Model:                           15\n",
       "Date:                       Sat, 11 Mar 2017   Pseudo R-squ.:                 0.09718\n",
       "Time:                               16:31:22   Log-Likelihood:                -3181.1\n",
       "converged:                              True   LL-Null:                       -3523.6\n",
       "                                               LLR p-value:                3.173e-136\n",
       "===================================================================================================\n",
       "                                      coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "cinc                                5.0679      0.635      7.979      0.000         3.823     6.313\n",
       "cinc_potential_opponent             7.7708      1.091      7.122      0.000         5.632     9.909\n",
       "defense                            -0.5988      0.115     -5.206      0.000        -0.824    -0.373\n",
       "neutrality                          0.3321      0.158      2.104      0.035         0.023     0.641\n",
       "nonaggression                      -0.4187      0.088     -4.743      0.000        -0.592    -0.246\n",
       "entente                            -0.3567      0.110     -3.254      0.001        -0.572    -0.142\n",
       "flow1                           -4.528e-05   1.01e-05     -4.464      0.000     -6.52e-05 -2.54e-05\n",
       "flow2                            7.236e-05    1.2e-05      6.016      0.000      4.88e-05  9.59e-05\n",
       "conttype_1.0                        1.2513      0.094     13.352      0.000         1.068     1.435\n",
       "conttype_2.0                        1.8963      0.425      4.464      0.000         1.064     2.729\n",
       "conttype_3.0                        1.7363      0.238      7.285      0.000         1.269     2.203\n",
       "conttype_4.0                        0.6842      0.240      2.848      0.004         0.213     1.155\n",
       "conttype_5.0                        0.6997      0.169      4.135      0.000         0.368     1.031\n",
       "allies_power                       -1.1480      0.592     -1.939      0.053        -2.309     0.012\n",
       "allies_power_potential_opponent     2.9889      0.543      5.502      0.000         1.924     4.054\n",
       "intercept                          -4.3954      0.141    -31.262      0.000        -4.671    -4.120\n",
       "===================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Run the regression per\n",
    "# http://blog.yhat.com/posts/logistic-regression-python-rodeo.html\n",
    "\n",
    "# Add intercept\n",
    "potential_conflicts_prepped['intercept'] = 1\n",
    "\n",
    "independent_vars = potential_conflicts_prepped.loc[:, ['cinc', 'cinc_potential_opponent', 'defense', 'neutrality', \n",
    "                                            'nonaggression', 'entente', 'flow1', 'flow2','conttype_1.0', \n",
    "                                            'conttype_2.0', 'conttype_3.0', 'conttype_4.0', 'conttype_5.0', \n",
    "                                            'allies_power', 'allies_power_potential_opponent',\n",
    "                                            'intercept']]\n",
    "logit = sm.Logit(potential_conflicts_prepped['fought_potential_opponent'], independent_vars)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccode</th>\n",
       "      <th>ccode_potential_opponent</th>\n",
       "      <th>fought_potential_opponent</th>\n",
       "      <th>year</th>\n",
       "      <th>stateabb</th>\n",
       "      <th>cinc</th>\n",
       "      <th>stateabb_potential_opponent</th>\n",
       "      <th>cinc_potential_opponent</th>\n",
       "      <th>StateNme</th>\n",
       "      <th>StateNme_potential_opponent</th>\n",
       "      <th>...</th>\n",
       "      <th>flow2</th>\n",
       "      <th>conttype_1.0</th>\n",
       "      <th>conttype_2.0</th>\n",
       "      <th>conttype_3.0</th>\n",
       "      <th>conttype_4.0</th>\n",
       "      <th>conttype_5.0</th>\n",
       "      <th>conttype_6.0</th>\n",
       "      <th>allies_power</th>\n",
       "      <th>allies_power_potential_opponent</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ccode, ccode_potential_opponent, fought_potential_opponent, year, stateabb, cinc, stateabb_potential_opponent, cinc_potential_opponent, StateNme, StateNme_potential_opponent, defense, neutrality, nonaggression, entente, flow1, flow2, conttype_1.0, conttype_2.0, conttype_3.0, conttype_4.0, conttype_5.0, conttype_6.0, allies_power, allies_power_potential_opponent, intercept]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 25 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_extra(x):\n",
    "    try:\n",
    "        return len(x) > 1\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "potential_conflicts_prepped[potential_conflicts_prepped['allies_power_potential_opponent'].apply(find_extra)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ccode', 'ccode_potential_opponent', 'fought_potential_opponent',\n",
       "       'year', 'stateabb', 'cinc', 'stateabb_potential_opponent',\n",
       "       'cinc_potential_opponent', 'StateNme', 'StateNme_potential_opponent',\n",
       "       'defense', 'neutrality', 'nonaggression', 'entente', 'flow1', 'flow2',\n",
       "       'conttype_1.0', 'conttype_2.0', 'conttype_3.0', 'conttype_4.0',\n",
       "       'conttype_5.0', 'conttype_6.0', 'allies_power',\n",
       "       'allies_power_potential_opponent', 'intercept'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potential_conflicts_prepped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potential_conflicts_prepped.columns.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
